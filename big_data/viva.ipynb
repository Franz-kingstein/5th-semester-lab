{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43a61b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/10/06 20:46:38 WARN Utils: Your hostname, kingstein, resolves to a loopback address: 127.0.1.1; using 10.192.7.224 instead (on interface wlp3s0)\n",
      "25/10/06 20:46:38 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/06 20:46:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+\n",
      "|Name|Age|Department|\n",
      "+----+---+----------+\n",
      "|John| 28|        HR|\n",
      "|Sara| 32|        IT|\n",
      "|Mike| 26|   Finance|\n",
      "|Nina| 29| Marketing|\n",
      "+----+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Viva_Assignment\").getOrCreate()\n",
    "\n",
    "data = [(\"John\",28,\"HR\"),\n",
    "        (\"Sara\",32,\"IT\"),\n",
    "        (\"Mike\",26,\"Finance\"),\n",
    "        (\"Nina\",29,\"Marketing\")]\n",
    "\n",
    "columns = [\"Name\",\"Age\",\"Department\"]\n",
    "\n",
    "df_employees = spark.createDataFrame(data,columns)\n",
    "\n",
    "df_employees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93672ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n",
      "| ID| Name|Marks|\n",
      "+---+-----+-----+\n",
      "|  1|Alice|   85|\n",
      "|  2|  Bob|   78|\n",
      "|  3|Cathy|   92|\n",
      "|  4|David|   66|\n",
      "+---+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "students_data = [\n",
    "    (1,\"Alice\",85),\n",
    "    (2,\"Bob\",78),\n",
    "    (3,\"Cathy\",92),\n",
    "    (4,\"David\",66)\n",
    "]\n",
    "\n",
    "student_columns = [\"ID\",\"Name\",\"Marks\"]\n",
    "\n",
    "df_students = spark.createDataFrame(students_data,student_columns)\n",
    "\n",
    "df_students.write.mode(\"overwrite\").option(\"header\",True).csv(\"students.csv\")\n",
    "\n",
    "\n",
    "df_students.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43a4eca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Columns:\n",
      "+-----+-----+\n",
      "| Name|Marks|\n",
      "+-----+-----+\n",
      "|Alice|   85|\n",
      "|Cathy|   92|\n",
      "|David|   66|\n",
      "|  Bob|   78|\n",
      "+-----+-----+\n",
      "\n",
      "Filtered (Mark > 80):\n",
      "+-----+-----+\n",
      "| Name|Marks|\n",
      "+-----+-----+\n",
      "|Alice|   85|\n",
      "|Cathy|   92|\n",
      "+-----+-----+\n",
      "\n",
      "Total number of Students:  4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_students = spark.read.csv(\"students.csv\",header = True,inferSchema = True)\n",
    "\n",
    "selected = df_students.select(\"Name\",\"Marks\")\n",
    "\n",
    "filtered = selected.filter(col(\"Marks\")>80)\n",
    "\n",
    "total_students = df_students.count()\n",
    "\n",
    "print(\"Selected Columns:\")\n",
    "selected.show()\n",
    "\n",
    "print(\"Filtered (Mark > 80):\")\n",
    "filtered.show()\n",
    "\n",
    "print(\"Total number of Students: \",total_students)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cbcdb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---------+----------+\n",
      "|Name|Age|     Dept|Experience|\n",
      "+----+---+---------+----------+\n",
      "|John| 28|       HR|   2 Years|\n",
      "|Sara| 32|       IT|   2 Years|\n",
      "|Mike| 26|  Finance|   2 Years|\n",
      "|Nina| 29|Marketing|   2 Years|\n",
      "+----+---+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "df_employee = df_employees.withColumn(\"Experience\", lit(\"2 Years\"))\n",
    "\n",
    "df_employee = df_employee.withColumnRenamed(\"Department\", \"Dept\")\n",
    "\n",
    "df_employee.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "668b9f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n",
      "| ID| Name|Marks|\n",
      "+---+-----+-----+\n",
      "|  3|Cathy|   92|\n",
      "|  1|Alice|   85|\n",
      "|  2|  Bob|   78|\n",
      "|  4|David|   66|\n",
      "+---+-----+-----+\n",
      "\n",
      "Average Marks: 80.25\n",
      "Maximum Marks: 92\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, max\n",
    "\n",
    "sorted_students = df_students.orderBy(col(\"Marks\").desc())\n",
    "sorted_students.show()\n",
    "\n",
    "avg_marks = df_students.select(avg(\"Marks\")).collect()[0][0]\n",
    "\n",
    "max_marks = df_students.select(max(\"Marks\")).collect()[0][0]\n",
    "\n",
    "print(\"Average Marks:\", avg_marks)\n",
    "print(\"Maximum Marks:\", max_marks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
